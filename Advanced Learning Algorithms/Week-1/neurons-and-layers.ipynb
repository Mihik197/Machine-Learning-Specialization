{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "code ported over from tensorflow to pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Regression/Linear Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function implemented by a neuron with no activation is the same as in Course 1, linear regression:\n",
    "$$ f_{\\mathbf{w},b}(x^{(i)}) = \\mathbf{w}\\cdot x^{(i)} + b \\tag{1}$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this is how models are defined in pytorch\n",
    "class LinearModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LinearModel, self).__init__()  # to initialize nn.Module class\n",
    "        self.linear = nn.Linear(1, 1)  # 1 input, 1 output\n",
    "\n",
    "    def forward(self, x):  # called when doing model(input_x)\n",
    "        return self.linear(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weights: tensor([[0.4991]])\n",
      "Initial bias: tensor([0.5060])\n"
     ]
    }
   ],
   "source": [
    "model = LinearModel()\n",
    "\n",
    "print(f\"Initial weights: {model.linear.weight.data}\")\n",
    "print(f\"Initial bias: {model.linear.bias.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "initialized with random weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial prediction: tensor([[300.]])\n"
     ]
    }
   ],
   "source": [
    "X_train_pt = torch.tensor([[1.0], [2.0]], dtype=torch.float32)\n",
    "Y_train_pt = torch.tensor([[300.0], [500.0]], dtype=torch.float32)\n",
    "\n",
    "a1 = model(X_train_pt[0].reshape(1, 1))  # converts it to 2D tensor\n",
    "print(f\"Initial prediction: {a1.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New weights: tensor([[200.]])\n",
      "New bias: tensor([100.])\n"
     ]
    }
   ],
   "source": [
    "# manually setting weights\n",
    "with torch.no_grad():  # to stop pytorch from tracking changes made in this block for autograd\n",
    "    model.linear.weight.fill_(200.0)\n",
    "    model.linear.bias.fill_(100.0)\n",
    "\n",
    "print(f\"New weights: {model.linear.weight.data}\")\n",
    "print(f\"New bias: {model.linear.bias.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New prediction: tensor([[300.]])\n"
     ]
    }
   ],
   "source": [
    "a1 = model(X_train_pt[0].reshape(1, 1))\n",
    "print(f\"New prediction: {a1.data}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In numpy:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Numpy prediction: [[300.]]\n"
     ]
    }
   ],
   "source": [
    "X_train_np = np.array([[1.0], [2.0]])\n",
    "Y_train_np = np.array([[300.0], [500.0]])\n",
    "\n",
    "\n",
    "set_w = np.array([[200.0]])\n",
    "set_b = np.array([[100.0]])\n",
    "\n",
    "# manually calculating the forward pass\n",
    "alin = np.dot(X_train_np[0].reshape(1, 1), set_w) + set_b\n",
    "print(f\"Numpy prediction: {alin}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch output:\n",
      "tensor([[300.],\n",
      "        [500.]])\n",
      "\n",
      "Numpy output:\n",
      "[[300.]\n",
      " [500.]]\n"
     ]
    }
   ],
   "source": [
    "predictions_pt = model(X_train_pt)\n",
    "predictions_np = np.dot(X_train_np, set_w) + set_b\n",
    "\n",
    "print(f\"PyTorch output:\\n{predictions_pt.data}\")\n",
    "print()\n",
    "print(f\"Numpy output:\\n{predictions_np}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get the same output on both!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# --------------------------------------------------------"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Neuron with sigmoid activation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function implemented by a neuron/unit with a sigmoid activation is the same as in Course 1, logistic  regression:\n",
    "$$ f_{\\mathbf{w},b}(x^{(i)}) = g(\\mathbf{w}x^{(i)} + b) \\tag{2}$$\n",
    "where $$g(x) = sigmoid(x)$$ "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = np.array([0., 1, 2, 3, 4, 5], dtype=np.float32).reshape(-1, 1)  # 2D matrix\n",
    "Y_train = np.array([0, 0, 0, 1, 1, 1], dtype=np.float32).reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in PyTorch\n",
    "class LogisticNeuron(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LogisticNeuron, self).__init__()\n",
    "        self.linear = nn.Linear(1, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Initial weight: tensor([[-0.1716]])\n",
      "Initial bias: tensor([0.8336])\n"
     ]
    }
   ],
   "source": [
    "model = LogisticNeuron()\n",
    "\n",
    "print(f\"Initial weight: {model.linear.weight.data}\")\n",
    "print(f\"Initial bias: {model.linear.bias.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated weight: tensor([[2.]])\n",
      "Updated bias: tensor([-4.5000])\n"
     ]
    }
   ],
   "source": [
    "with torch.no_grad():\n",
    "    model.linear.weight.fill_(2.0)\n",
    "    model.linear.bias.fill_(-4.5)\n",
    "\n",
    "print(f\"Updated weight: {model.linear.weight.data}\")\n",
    "print(f\"Updated bias: {model.linear.bias.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PyTorch model prediction: tensor([[0.0110]])\n"
     ]
    }
   ],
   "source": [
    "prediction_pt = model(torch.from_numpy(X_train[0].reshape(1, 1)))\n",
    "# torch.from_numpy() to convert numpy array to pytorch\n",
    "\n",
    "print(f\"PyTorch model prediction: {prediction_pt.data}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in numpy\n",
    "\n",
    "def sigmoid_np(x):\n",
    "    return 1 / (1 + np.exp(-x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Manual numpy prediction: [[0.01098694]]\n"
     ]
    }
   ],
   "source": [
    "set_w = np.array([[2.0]])\n",
    "set_b = np.array([-4.5])\n",
    "alog = sigmoid_np(np.dot(set_w, X_train[0].reshape(1, 1)) + set_b)\n",
    "print(f\"Manual numpy prediction: {alog}\")\n",
    "# almost same output"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
